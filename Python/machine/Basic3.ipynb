{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력값 1개, 출력값 1개: y = w1 * X1 + bias\n",
    "### 입력값 2개, 출력값 1개: y = w1 * X1 + w2 * X2 + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autosave 0 \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 파일 로딩\n",
    "from tensorflow.keras.layers import Dense       # 전결합층\n",
    "from tensorflow.keras.optimizers import Adam    # 가중치, bias 최적화\n",
    "from tensorflow.keras.utils import plot_model   # 네트워크 입출력 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "rc('font', family='Malgun Gothic')\n",
    "\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[[ 1 10]\n",
      " [ 2 10]\n",
      " [ 3 10]\n",
      " [ 4 10]\n",
      " [ 5 10]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = []\n",
    "for i in range(1, 101):\n",
    "    x_train.append([i, 10])\n",
    "\n",
    "x_train = np.array(x_train)    \n",
    "print(x_train.shape)\n",
    "print(x_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "[[ 68.]\n",
      " [143.]\n",
      " [218.]\n",
      " [293.]\n",
      " [368.]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 -> 실제값, Target\n",
    "# 1, 10 -> 68.0  2, 10 -> 143.0  3, 10 -> 218.0\n",
    "y_train = []\n",
    "for i in range(len(x_train)):\n",
    "    target = x_train[i][0] * x_train[i][1] / 2 * 5 * 3 - 7\n",
    "    # print(target)\n",
    "    y_train.append([target])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 12740478.5185 - val_loss: 40519652.0000\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9232834.1451 - val_loss: 25548958.0000\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4781181.2438 - val_loss: 7425111.0000\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1242453.1535 - val_loss: 1046987.8125\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 148670.4818 - val_loss: 302224.4375\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 109027.8657 - val_loss: 263384.0625\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 96280.1852 - val_loss: 237968.0469\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 91178.1894 - val_loss: 184596.3281\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 89165.2256 - val_loss: 149196.2188\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 65558.0415 - val_loss: 153539.0312\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 60543.4216 - val_loss: 128372.9375\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 58385.8932 - val_loss: 68867.1719\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 36659.4554 - val_loss: 124034.2969\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31773.5552 - val_loss: 49257.9492\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24676.3544 - val_loss: 56427.2109\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23334.3658 - val_loss: 42878.8750\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16957.3415 - val_loss: 43018.7344\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 12553.8301 - val_loss: 29027.8652\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9669.5264 - val_loss: 20550.2285\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7407.1189 - val_loss: 14869.0371\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6056.0027 - val_loss: 9946.4053\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3690.5789 - val_loss: 7431.1240\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3205.7351 - val_loss: 3974.9954\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1941.9570 - val_loss: 2882.5754\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1212.0021 - val_loss: 3315.7378\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 863.2836 - val_loss: 926.8498\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 566.4028 - val_loss: 1223.2498\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 333.1317 - val_loss: 496.3652\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 199.0557 - val_loss: 295.5188\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 125.0068 - val_loss: 137.1467\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 65.9267 - val_loss: 104.9504\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 33.5766 - val_loss: 45.2442\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 18.7734 - val_loss: 41.0832\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.5195 - val_loss: 16.9701\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7265 - val_loss: 3.1885\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8263 - val_loss: 2.4259\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0291 - val_loss: 2.4056\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 0.6454\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2420 - val_loss: 0.3639\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.1004\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0215\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0154\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.1709e-04 - val_loss: 4.7381e-04\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2610e-04 - val_loss: 8.7500e-05\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.8442e-05 - val_loss: 7.6342e-05\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8492e-05 - val_loss: 1.8144e-05\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.9128e-06 - val_loss: 5.2452e-06\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8024e-06 - val_loss: 1.9908e-06\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.9361e-07 - val_loss: 2.2531e-06\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.3187e-07 - val_loss: 2.0623e-06\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1216e-07 - val_loss: 1.5616e-06\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0493e-07 - val_loss: 6.1989e-07\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5851e-07 - val_loss: 5.6028e-07\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3726e-07 - val_loss: 5.2452e-07\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6092e-07 - val_loss: 3.4571e-07\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2770e-07 - val_loss: 3.5763e-07\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1348e-07 - val_loss: 2.3842e-07\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4429e-07 - val_loss: 2.3842e-07\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.5923e-08 - val_loss: 2.3842e-07\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.1811e-08 - val_loss: 2.7418e-07\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0159e-07 - val_loss: 1.5497e-07\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.5077e-08 - val_loss: 1.9073e-07\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 9.6189e-08 - val_loss: 1.6689e-07\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.4348e-08 - val_loss: 1.5497e-07\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.5176e-08 - val_loss: 2.5034e-07\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0824e-08 - val_loss: 1.4305e-07\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.3097e-08 - val_loss: 1.4305e-07\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.6600e-08 - val_loss: 1.4305e-07\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0665e-08 - val_loss: 1.0729e-07\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0600e-08 - val_loss: 1.3113e-07\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.0262e-08 - val_loss: 9.5367e-08\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7251e-08 - val_loss: 1.0729e-07\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4122e-08 - val_loss: 1.0729e-07\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1608e-08 - val_loss: 1.0729e-07\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6570e-08 - val_loss: 1.0729e-07\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6961e-08 - val_loss: 1.0729e-07\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1342e-08 - val_loss: 1.0729e-07\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.5630e-08 - val_loss: 1.0729e-07\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5602e-08 - val_loss: 1.1921e-07\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8961e-08 - val_loss: 1.0729e-07\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2352e-08 - val_loss: 1.0729e-07\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7412e-08 - val_loss: 1.0729e-07\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1641e-08 - val_loss: 1.9073e-07\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.8791e-08 - val_loss: 1.0729e-07\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.5392e-08 - val_loss: 1.5497e-07\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.2480e-08 - val_loss: 4.2915e-07\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.7471e-08 - val_loss: 1.0729e-07\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.8085e-08 - val_loss: 5.9605e-08\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.3673e-08 - val_loss: 7.1526e-08\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7098e-08 - val_loss: 4.7684e-08\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0602e-08 - val_loss: 8.3447e-08\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.2663e-08 - val_loss: 1.0729e-07\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0936e-08 - val_loss: 1.5497e-07\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7446e-08 - val_loss: 1.0729e-07\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.8388e-08 - val_loss: 9.5367e-08\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.6450e-08 - val_loss: 8.3447e-08\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.8320e-08 - val_loss: 1.0729e-07\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.9755e-08 - val_loss: 1.6689e-07\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.2780e-08 - val_loss: 1.1563e-06\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3960e-07 - val_loss: 1.9073e-07\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.5825e-08 - val_loss: 1.4305e-07\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.7262e-08 - val_loss: 9.5367e-08\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7883e-07 - val_loss: 1.4305e-07\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1964e-07 - val_loss: 4.7922e-06\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.4366e-06 - val_loss: 9.1434e-06\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.1584e-07 - val_loss: 9.5367e-08\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8722e-07 - val_loss: 2.3246e-06\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0020e-07 - val_loss: 1.5497e-07\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4561e-07 - val_loss: 2.2650e-07\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.9091e-08 - val_loss: 1.1921e-07\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7537e-07 - val_loss: 2.9087e-06\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0373e-06 - val_loss: 1.3924e-05\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.5905e-06 - val_loss: 1.8358e-06\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4166e-06 - val_loss: 1.0014e-06\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3496e-06 - val_loss: 1.3113e-07\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.1662e-08 - val_loss: 3.9339e-07\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.1789e-07 - val_loss: 9.6560e-07\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.3657e-06 - val_loss: 3.7423e-04\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 7.7343e-05\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4114 - val_loss: 10.5190\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9478 - val_loss: 21.8369\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.9430 - val_loss: 0.0031\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.1433\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1672 - val_loss: 5.2282\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6359 - val_loss: 2.2945\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 819.4649 - val_loss: 337.6880\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 150.0438 - val_loss: 115.0900\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.1375 - val_loss: 0.0053\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7517e-04 - val_loss: 4.0698e-05\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7176e-06 - val_loss: 2.7061e-06\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.1856e-07 - val_loss: 1.7881e-07\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5942e-07 - val_loss: 9.5367e-08\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9114e-07 - val_loss: 1.5616e-06\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.2010e-07 - val_loss: 3.2544e-06\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6105e-07 - val_loss: 3.4571e-07\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2491e-07 - val_loss: 2.5272e-06\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.0420e-07 - val_loss: 2.9445e-06\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.2200e-07 - val_loss: 4.0174e-06\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.9631e-06 - val_loss: 8.1062e-07\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.2079e-07 - val_loss: 3.6955e-07\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.7429e-07 - val_loss: 2.6226e-07\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0200e-05 - val_loss: 5.8413e-06\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.4431e-06 - val_loss: 0.0010\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.1969e-04 - val_loss: 5.0902e-05\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.8293e-05 - val_loss: 6.4126e-04\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 6.9437e-04 - val_loss: 1.5516e-04\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7253e-04 - val_loss: 0.0024\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7200e-04 - val_loss: 1.3927e-04\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2163e-05 - val_loss: 2.8467e-05\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.3061e-06 - val_loss: 1.8597e-06\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1562e-05 - val_loss: 0.0034\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 7.6345e-04\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0810\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.2633\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 469.9271 - val_loss: 12182.0186\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2193.8724 - val_loss: 12.4397\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7910 - val_loss: 0.2047\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 5.0176e-04\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0784e-05 - val_loss: 1.4305e-07\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8640e-07 - val_loss: 6.4373e-07\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2270e-07 - val_loss: 1.5497e-07\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.3099e-08 - val_loss: 1.9073e-07\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.2995e-08 - val_loss: 1.9073e-07\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.4643e-08 - val_loss: 1.1921e-07\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3210e-07 - val_loss: 4.3702e-05\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9167e-06 - val_loss: 2.3007e-06\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.4329e-07 - val_loss: 1.5497e-07\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0138e-06 - val_loss: 1.6689e-07\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.1417e-07 - val_loss: 1.0729e-07\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.6444e-08 - val_loss: 1.1921e-07\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.4615e-08 - val_loss: 3.2187e-07\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.3650e-07 - val_loss: 2.0385e-06\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.2639e-07 - val_loss: 1.1921e-07\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.3959e-07 - val_loss: 6.0797e-07\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5909e-07 - val_loss: 2.1458e-07\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3176e-07 - val_loss: 2.5034e-07\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.6196e-08 - val_loss: 1.4305e-07\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.5247e-08 - val_loss: 1.4305e-07\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.4794e-06 - val_loss: 8.5664e-05\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.9507e-06 - val_loss: 5.1808e-05\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.3330e-06 - val_loss: 1.9073e-07\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5859e-05 - val_loss: 0.0012\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 9.0404e-05 - val_loss: 2.9945e-04\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.2659e-04 - val_loss: 0.0046\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.8260e-04 - val_loss: 1.5551e-04\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0881e-04 - val_loss: 0.0018\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5125e-04 - val_loss: 0.0040\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 1.4746e-04\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2380e-05 - val_loss: 2.9683e-06\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3146e-05 - val_loss: 1.1003e-05\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.8067\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8989 - val_loss: 1.1258\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8665 - val_loss: 1.0491\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8571 - val_loss: 21.3602\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 10.4702 - val_loss: 0.0050\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.3209\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1368 - val_loss: 3.3499\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9823 - val_loss: 15.1293\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 443.9482 - val_loss: 64.4598\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5681 - val_loss: 0.0934\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0294 - val_loss: 0.0162\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 3.3131e-04\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7917e-05 - val_loss: 5.6028e-06\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0397e-06 - val_loss: 7.6771e-06\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7905e-07 - val_loss: 1.1921e-07\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.9783e-08 - val_loss: 1.5497e-07\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.0390e-08 - val_loss: 1.3113e-07\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 8.4218e-08 - val_loss: 7.9870e-07\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.4433e-08 - val_loss: 1.2875e-06\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7520e-07 - val_loss: 1.5497e-07\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0826e-06 - val_loss: 2.7537e-06\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.0200e-07 - val_loss: 7.3671e-06\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.0307e-06 - val_loss: 8.8096e-06\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4835e-06 - val_loss: 5.2381e-05\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4941e-05 - val_loss: 8.6900e-04\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9881e-04 - val_loss: 5.9366e-06\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9641e-04 - val_loss: 0.0015\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0107\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 5.5279e-04\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.7240e-04 - val_loss: 6.4373e-07\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8694e-05 - val_loss: 5.4669e-05\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.9478e-05 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.2170e-04 - val_loss: 0.0060\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.3715\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 9.3397\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 325.6136 - val_loss: 13784.2939\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 524.4851 - val_loss: 47.8505\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.2592 - val_loss: 0.0080\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0120\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 1.3570e-04\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0483e-06 - val_loss: 1.2708e-04\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.1309\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 1.6689e-07\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0006e-05 - val_loss: 2.4630e-04\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1909e-05 - val_loss: 1.2517e-06\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0116e-05 - val_loss: 5.1737e-06\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.8878e-06 - val_loss: 1.0359e-05\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3681e-06 - val_loss: 1.0393e-04\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.2199e-05 - val_loss: 5.1975e-06\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7325e-06 - val_loss: 2.9683e-05\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.9590e-05 - val_loss: 0.0024\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.2360\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 2.8787\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.308 - 0s 1ms/step - loss: 3.6725 - val_loss: 3.0286\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.3800\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0029\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 3.9066e-04\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 1.6652\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5903 - val_loss: 97.2894\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 147.1384 - val_loss: 7219.7627\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1700.2532 - val_loss: 50.2115\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.5773 - val_loss: 0.0092\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 7.7009e-06\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.9150e-06 - val_loss: 5.4121e-06\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.1071e-07 - val_loss: 1.0729e-07\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.9422e-08 - val_loss: 1.6689e-07\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.5077e-08 - val_loss: 1.5497e-07\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.4976e-08 - val_loss: 9.5367e-08\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7649e-07 - val_loss: 1.0538e-05\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4038e-06 - val_loss: 4.4823e-06\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6285e-06 - val_loss: 2.3842e-07\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.6322e-07 - val_loss: 1.6439e-05\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.0335e-06 - val_loss: 7.1526e-08\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.5743e-07 - val_loss: 1.4758e-05\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0684e-05 - val_loss: 9.5606e-06\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.7676e-07 - val_loss: 1.1408e-05\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6706e-05 - val_loss: 1.3113e-07\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.5567e-06 - val_loss: 5.3644e-07\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.2038e-06 - val_loss: 7.0035e-05\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.8953e-05 - val_loss: 1.2028e-05\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.0109e-06 - val_loss: 6.5088e-06\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.9241e-06 - val_loss: 8.5473e-06\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.8015e-06 - val_loss: 2.1458e-07\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9116e-07 - val_loss: 1.3113e-07\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.8139e-07 - val_loss: 2.0266e-07\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9785e-04 - val_loss: 8.6808e-05\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0106\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 1.1336e-04\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.7942e-06 - val_loss: 7.0810e-06\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.5739e-05 - val_loss: 0.0070\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2404 - val_loss: 101.0674\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 63.5484 - val_loss: 0.8574\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3782 - val_loss: 303.3563\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 969.3574 - val_loss: 207.8485\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 289.5260 - val_loss: 188.5759\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 94.3347 - val_loss: 0.1532\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.4429 - val_loss: 0.7322\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1896 - val_loss: 0.0961\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0011\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2582e-04 - val_loss: 1.2636e-06\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7899e-06 - val_loss: 2.2650e-07\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.5907e-08 - val_loss: 1.8954e-06\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.8416e-06 - val_loss: 7.5102e-07\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7.4445e-07 - val_loss: 2.1458e-07\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5.3877e-06 - val_loss: 6.3658e-06\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.9749e-05 - val_loss: 2.2376e-05\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6663e-05 - val_loss: 6.9737e-06\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.6538e-06 - val_loss: 2.9516e-05\n"
     ]
    }
   ],
   "source": [
    "# model 제작\n",
    "try:\n",
    "    if model != None:\n",
    "        print('model 객체 삭제')\n",
    "        del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = Sequential() # 객체 생성\n",
    "# Dense: 전결합층, 1: 출력노드(뉴런), input_dim=2: 입력 데이터 종류 수\n",
    "# activation='linear': 선형회귀\n",
    "model.add(Dense(10, input_dim=2, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# optimizer='adam': 오차 역전파(weight(기울기), bias(편향) update)차\n",
    "# loss='mse': 손실 측정 함수\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mse')\n",
    "model.summary() # 네트워크 확인\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 45488876.0000]) # 값을 반영하여 변경 ★\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# train loss: 하강하면 훈련이 정상적으로 진행되고 있음\n",
    "# val loss: 하강하면 훈련되지 않은 데이터를 대상으로 한 테스트도 정상적으로 진행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEnCAYAAABcy78jAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3dXWwbV3o38D/jOP1CS8EtqGxUKMDCtWEgBeMs6gjdtIZlAwsbGXr7Ia8oV3Ev6GBUdF3nNS+yLAXBsKrkggKM5MICpZuAkClEF7vLQdcoIAuwUUT0AinItrmwsHBA7zYNecVBgAJtkD3vhXImM8MZakiRnCH5/wGEzZnhmcMhNQ/nnDPPCQkhBIiIiBw843cFiIgouBgkiIjIFYMEERG5YpAgIiJXz9oXfP7553jrrbfw1Vdf+VEfIiLyyezsLBRFsSxruJLY3t7GxsZGzypF1K8ePXqER48e+V2NvrC5uYmnT5/6XQ1qYnNz0/Hc33AlIX344YddrRBRv7t8+TIAYH193eeaBF8oFMK1a9cwMzPjd1XIhfw+27FPgoiIXDFIEBGRKwYJIiJyxSBBRESuGCSIiMgVgwRRAMzPz2N+ft7vagRGKBSyPJzUajUsLy/3uGb+Wl5ehq7rjuu8HLN2MEgQEXRd7+iJpVOEEHBKVF2r1bCwsICTJ08aJ0W3IGs/eQbxfUpPnz7F3NwcQqEQ5ubmsL29bVl/7tw5zM7OolarNbzW7VgdFIMEUQDcunULt27d8m3/Dx8+9G3frdJ1HYlEAleuXMHk5CTq9Try+TwWFxcdA4UQAtVqFQBQrVa7ciLtBF3XUS6XcefOHdTrdZw+fRpnz56FpmnGNtFoFKlUColEwvWKotMYJIiGnK7rWF1d9bsanq2trSEajWJiYgIAEA6HMT09DQBYXFx0vGs4EolY/g2ihw8fGikxzO8pFotZtpuYmMDY2BjW1tZ6Ui8GCSKf1Wo1bGxsGCcD+3NN0xAKhRCLxYzUFrVaDZqmGdusrq4aTRS7u7tG2U5NLPZlmUzG+LVqXh7EfpJarYZkMokzZ844rs9kMojH455TC+m6jo2NDeN9r66uWppyvHwW5m2Xl5eN9famov3YcyZJqqo2LJuamkIymXRsduo4YbO+vi4cFhORzczMjJiZmTlwOYqiCADG3535+c7OjhBCiEqlIgAIVVWFEMJYb96mXq8LVVUFAPH48WMhhBDVatVStrks8zL7cyGESKfTIp1OH/j9yfLX19db2t7pPFQoFAQAUalUHF8jxF69AYhSqeS43kxRFJHNZoUQe8dKURShKIqo1+vG+v0+C/Nr8/m8EEKI+/fvO9ahFfV6XQAQhUKhYZ2sg9M6t2O3H7fvM4MEUZs6FSSEaPzDdvpD97JNqVQSAEQmkzlwWZ3UqSAhA4Dba4TYO7nKk7sMlub1kjyRV6tVY9nOzo4AYJzs3epiX5bP5x23OUiQvX//viVgmckAYv6cm9XXC7fvM5ubiAZINBoFACSTSZ9r0h2Li4v7bhMOh432+mZNMpubmwCs/RQnTpwAANy9e7elesnt7U15Xurr5vbt20ilUgiHww3r5LJefM4MEkQ0cCKRCEqlEjRNcx0JtLKy0rBMnnzNI4q8kNuLr4ehmh/t2NjYgKIoRue8nxgkiAaQU2fnsIlGoygUCtA0DZlMpmG97Ch2utJo9/iZBw20q1wu45NPPsHVq1cPXFYnMEgQDRB5krpw4YLPNekOebL3eo+AoijGPRR2cm6LJ0+eGMtkuVNTUy3VK5vNAgByuZxRRjt3hNdqNWxtbVnumSmXy5ibm3PcPp1Ot1R+OxgkiHxmH3Jpfi5POOaTov2Xrxzuqes6crkcFEWxDKeUv4plACkWi8Y6efIx/6qWJ7YgDoE9duwYgMYgIY+J01XB9PS048n0/PnzUBQFS0tLxuvu3bsHVVUxOTnZUF6zz+LixYsA9vogRkZGEAqFMDo6agQbOTS2XC67vrdarYZEIoFkMmnp23j55Zcbgr4cfnvq1CnX8jqFQYLIZ6Ojo5b/m5+PjIxY/rVvD+x1tsZiMYyMjGB8fBy5XM6y/kc/+hEURcHx48ehaRomJiaMX9g3b94EAOOX6/vvv4/Z2dnOvsEOevXVVwEAn332mbFMnpCBvWPjlHbj1q1bDfchyA5uRVEsr3v33XeNbbx+FpFIBJVKxQhGqqqiUqlgfHwcAFCv16GqatOgu7Cw4NoXcvz4cctz+f7l8eimkLD1rNy9exeXL18O7K3rREHh9/Sl8qTWD3+roVAI6+vrnqcvbfbe5JXOjRs3WqqDruuOI4V6KRaLoVAoHLic+fl5jIyMOB6Ddr8Xbt9nXkkQUV9JJBJ48OCBpdnMC78DRLFYRCqVOnA55XIZ5XIZiUSiA7XaH4MEUR+y92MME9lMtLS01LSNP0i2t7dx5MiRAw9p3d3dxcrKCtbW1noW9LoWJOw5T/pNEDvtiCR7P8agckvtHYlEkMvlsLW15UOtWjc5OWl0uh+Epmm4efOmY6LCbqVBf7bjJX5tYWHB8WYV8kbXdYyMjLTUruj2BfGjzdpe/yDVbRAM+nHz8v7C4XDL/RL9rtn77dZ3omtXEnfu3OlW0T3Rj/n9hRCo1+vG83q97tvJxF5/YcrpD/hbNyLyjn0SAXSQ/P7mdkq/Ourc6m++RPa7E5GIvOlYkDDnZY/FYq63p7vlXG8lb7t8vcz9bm/KOGhe90HL7x+U+rdCBhrz1JTmz1U+zHe0mteZ35fb902+X13XMTc3xz4oIif2tLDtpgpXFEWoqmqktZWpc81lNcu57jVveyaTMXLJ1+v1htTBncjr3u/5/e2vDUr9my23k/utVqsNdZXpnM3fC/N7lamfW/m+lUolx/Ka6WSq8EGHFlOFU+91dT4JORGIOXe7zHduLmu/nOtOJxCnk485/7s8aXndh1deTnpetvEjv7+X8v2qv9f3lU6nLSdt++symYwArJPPlEolyzwAXr9vTvn6vWCQ8I5BIvi6GiTkr76Gwpv8orU/nLZ3Wib3lc/nHf+499uHV50KEp0uq526B6n+rb6vSqViBATz62TwkrOKCWG9yhSive9bK2ZmZlzL54OPfnw4BYmODIH1OtTVnHO9XW+99Rb+67/+C/F4HMBe+7d5WFgn9kHBsLq6aqR5tk+uEo1Goaoq3nzzTVy6dAkA8Itf/MLIlQP05rvw2muv4dq1a10rf1BcunQJ165dw2uvveZ3VcjFe++957zCHjXauZLA11Fov+XyublZar9y3MqWbciAc1OI2z68cqt7q9vI5c2aTlopq526B6n++70vuR/ZVCSvDJxeJ68m8vm8KBQKRl+KfV+tfN9aweYm7wA2NwVdV6cvlbnU97tFvhM510OhEHRdRzQaxZ07d1AqlSy/MjuV171T+j2/fy/rXywWcfr0aQAwrhTNVwZ28moiHo9jdXW1IeVB0L4LRH3JHjXauZKQo08URTF++cmRJDD9CjWPjDE/KpWKZZ3sazB3fsvOamCv41HuR7ZZS8324ZW5jGq12lLdgG8mUZejrxRFsZRvHzEkR+uYj5VsT69Wq8b78zK6yVwvWdeg1N9pZJQky5Cj0OTrK5WKePz4cUNd7a8z901IXr9v7eKVhHfglUTgdbXjWoi9k7U8eaiqahl+aP7DrlQqxrBVVVUbmhPMf7huy+SJB7ampv324ZXTicVr3eSJTp7kstlsQwd7pVIx1hcKBSGEaDhWsiklnU4by/YLEvvV28/6e62b3Jf99XK0k9NnqSiKa5OSl++bPQh6xSDhHYNE8Ll9nzmfRAf1U35/J/1Yf13X8fbbb/uSBsbv+ST6SavzSVDvcT4JGkgffvhhy/MRE5F3DBId0u/5/fup/vPz85b0G3I+Yhoc5tQrbmldhnEQwvLycsP83pKXY9aOoQoS9oPo9mhHv+f376f6yxFP2WzW10y9ftN1vSvzB/SqfC/EXr9pw/JarYaFhQWcPHnSkt/LSaf+xnvh6dOnmJubM/Km2fPOnTt3DrOzs44/5NyO1UENVZCQB3G/RyfK7jf9VP+rV69CCIGrV6/6XRVftZNOPkjlt0vXdSQSCVy5cgWTk5Oo1+vI5/NYXFx0DBRCfJOmvlqtBvb7res6yuUy7ty5g3q9jtOnT+Ps2bPGTaHA3rDvVCqFRCLhekXRaUMVJIgGxUHSyQeh/INYW1tDNBo17osJh8OYnp4GACwuLmJjY6PhNTJNvdOMbkHx8OFDKIoCwPqe7LN7TkxMYGxsDGtraz2pF4MEUY+Z0+qbU95L7aZjD3K6+k6p1WpIJpM4c+aM4/pMJoN4PO4YKJzs91m0MoXBQacokAHCTlXVhmVTU1NIJpM96T9kkCDqsdnZWXzxxRdGM4imaZbmA/MMflKlUrE8N/fFyCbC0dFRxGIxaJqGYrGIq1evGjMVHj9+3AgU7ZYfBI8ePQIAHD161HH9jRs3kE6nEY/H980AAez/WSQSCcTjceOYKoqCSqUCTdPwzjvvGOXUajUkEgmMjY1BCIHr16/j7NmznurgRtbBKduBfP/yeHSV/caJdm+mIxo27dxMJzMRmG8wlXeNm9Ocw+FucPsyL9sI4U+6eju0eDOd277t88fYXyPEXqYAebOn+SZL++s6+Vl0aooCe/0URXHMdi0zJjjdTNzu59bV3E1E5M3m5iYAa9v4iRMnAOzdyNoN0WgUABoy6fajxcXFfbcJh8NGe32zJplOfhZye3uznZf6url9+zZSqZTjVL9yWS8+UwYJoh5ySqsv/+DNo1joYCKRCEqlUkPzkVknPwtzWnr7ox0bGxtQFKUhaaUfGCSIekh2Tjr9unXqoOykbpcfNNFoFIVCwZiTxK4bn4V5gEC7yuUyPvnkk8AM8WaQIOohmbvoyZMnxjL5K7db6UX6PV29mTzZe71HQFEU4x4Ku05+Fp1KS1+r1bC1tWUZOFAulzE3N+e4fTqdbqn8djBIEPXQ+fPnoSgKlpaWjF+w9+7dg6qqlvQi8pesPMEXi0VjnTxhmH8J209GcgioruvI5XJQFMUyxLLd8v0eAnvs2DEAjUFCHkunq4Lp6WnHk6mXz8Jcntyned9y/cWLFwHs9UGMjIwgFAphdHTUCDZyaGyz0U5yhFQymbT0bbz88ssNAV4Ovz116pRreR1j78nm6CYib9pNFV6tVkU2mzVGoTjN195uOnlZpl/p6t2gQ6ObZNp58yyEclvzw4lTSvj9Pgunct321WyKApnqvllaejnVgtPDngpfjsKyz69irl+rmCqcqMOCmCo8qOneW00V3ux9yKsa89z2Xui67jhSqJdisRgKhcKBy5mfn8fIyIjjMWj3O8BU4UQ0EBKJBB48eGBpIvPC7wBRLBaRSqUOXE65XEa5XEYikehArfbHIEE0IPop3ftByPsglpaWDnRHcy9tb2/jyJEjBx7Suru7i5WVFaytrfUs6DFIEA2Ifkr37pVbau9IJIJcLoetrS0fatW6yclJo9P9IDRNw82bNx0TFXYrDfqzHS+RiHwRtH6Ig/DyXsLhcMv9Ev2u2fvt1ufPKwkiInLFIEFERK4YJIiIyBWDBBERuXLtuJZpdInImUyNwL8Vbx49eoTDhw/7XQ1ysbm56Zyzyn4L9qNHj1xvDeeDDz744GNwH//4j/+4f1oOomHWavoIokHHPgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInL1rN8VIPJLqVTCv/zLvzQs1zQNv/zlL43nR48exV/91V/1smpEgRESQgi/K0Hkh3/4h3/Ae++9h9/4jd9w3eZ///d/AQD8M6FhxeYmGlp/+Zd/CWAvELg9nnvuOfz93/+9zzUl8g+vJGho/frXv8bY2Bg+//zzptv967/+K7773e/2qFZEwcIrCRpazzzzDC5fvoznnnvOdZsXXngBf/qnf9rDWhEFC4MEDbV4PI7/+7//c1x3+PBhvPHGGwiFQj2uFVFwsLmJht63v/1tfPrpp47r/v3f/x1//Md/3OMaEQUHryRo6P3t3/4tDh8+3LD8j/7ojxggaOgxSNDQi8fj+PLLLy3LDh8+jCtXrvhUI6LgYHMTEYBoNIr/+I//MO6HCIVC+MUvfoFvf/vbPteMyF+8kiACcOXKFRw6dAjAXoB45ZVXGCCIwCBBBACYnp7GV199BQA4dOgQZmdnfa4RUTAwSBBh736IP/uzPwOwd5PdD37wA59rRBQMDBJEX7t8+TIA4Dvf+Q6ef/55n2tDFAx93XGdTqfxT//0T35Xg4jI1XPPPWckiuxHfZ0q/NNPP8Xhw4exvr7ud1WoC9577z0AwLVr13q2T13X8Xu/93t9d5f1pUuXcO3aNbz22mt+V4VM7t69i5/85Cd+V+NA+jpIAMDU1BSmpqb8rgZ1gfzj4ufrzauvvspjFTBffvll3wcJ9kkQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQoKEwPz+P+fl5v6vRN2q1GpaXl/2uRk8tLy9D13W/qxE4DBJEPaDret/ce1Gr1bCwsICTJ08iFAohFAq5Bli53vwIqqdPn2Jubg6hUAhzc3PY3t62rD937hxmZ2dRq9V8qmEwMUjQULh16xZu3brl2/4fPnzo275boes6EokErly5gsnJSdTrdeTzeSwuLjoGCiEEqtUqAKBarSKoCRx0XUe5XMadO3dQr9dx+vRpnD17FpqmGdtEo1GkUikkEgleUZgwSBB1ma7rWF1d9bsanqytrSEajWJiYgIAEA6HMT09DQBYXFzExsZGw2sikYjl3yB6+PAhFEUBYH1PsVjMst3ExATGxsawtrbW8zoGFYMEDbxarYaNjQ3jhGB/rmkaQqEQYrEYnj59amyjaZqxzerqqtFMsbu7a5Tt1MxiX5bJZIxfrOblQesnqdVqSCaTOHPmjOP6TCaDeDzuGCic6LqOjY0N4z2vrq5amnK8fA7mbZeXl4319qai/cgAYaeqasOyqakpJJNJNjtJoo/NzMyImZkZv6tBXdKpz1dRFAFAyK+7+fnOzo4QQohKpSIACFVVhRDCWG/epl6vC1VVBQDx+PFjIYQQ1WrVUra5LPMy+3MhhEin0yKdTh/4/cny19fXD1RGoVAQAESlUnEsX4i9OgMQpVLJcb2Zoigim80KIfaOk6IoQlEUUa/XjfX7fQ7m1+bzeSGEEPfv33esQyvq9boAIAqFQsM6WQenda1aX193PDb9pK9rzyAx2Dr5+Xo5aXvZplQqCQAik8kcuKxO6kSQkAHArXwh9k6u8uQuA6V5vSRP5NVq1Vi2s7MjABgne/m6/Y5dPp933OYgAfb+/fuWgGUmA4j5M27XIAQJNjcRtSAajQIAksmkzzXpvMXFxX23CYfDRnt9syaZzc1NANZ+ihMnTgDYy4zaCrm9vRnPS33d3L59G6lUCuFwuGGdXDaIn3E7GCSIqCWRSASlUgmaprmOBFpZWWlYJk++5hFFXsjtxV7Lh+XRjo2NDSiKYnTOU3MMEkRtcOrwHCbRaBSFQgGapiGTyTSslx3FTlca7R4784CBdpXLZXzyySe4evXqgcsaFgwSRC2QJ6oLFy74XJPOkyd7r/cIKIpi3ENhNzMzAwB48uSJsUyW2+qcF9lsFgCQy+WMMtq5I7xWq2Fra8tyv0y5XMbc3Jzj9ul0uqXyBxWDBA08+7BL83N50jGfGO2/fuWQT13XkcvloCiKZUil/GUsA0ixWDTWyROQ+Ze1PLkFbQjssWPHADQGCXk8nK4KpqenHU+m58+fh6IoWFpaMl537949qKqKycnJhvKafQ4XL14EsNcHMTIyglAohNHRUSPYyKGx5XLZ9b3VajUkEgkkk0lL38bLL7/cEPDl8NtTp065ljdMGCRo4I2Ojlr+b34+MjJi+de+PbDX4RqLxTAyMoLx8XHkcjnL+h/96EdQFAXHjx+HpmmYmJgwfmXfvHkTAIxfr++//z5mZ2c7+wY75NVXXwUAfPbZZ8YyeUIG9o6LU9qNW7duNdyHIDu4FUWxvO7dd981tvH6OUQiEVQqFSMYqaqKSqWC8fFxAEC9Xoeqqk0D7sLCgmtfyPHjxy3P5fuXx2PYhUS7vT8BcPnyZQDgHNcDyu/PV57Y+uFPJBQKYX193WjmaZe8yrlx40ZLr9N13XGkUC/FYjEUCoUDlzM/P4+RkZGWj4GTu3fv4vLly33xHXLDKwkiMiQSCTx48MDSZOaF3wGiWCwilUoduJxyuYxyuYxEItGBWg0GBgk0pgcgsvdjDAvZTLS0tNS0jT9Itre3ceTIkQMPad3d3cXKygrW1tZ8D3pB8qzfFQiChYUFx3HdQdcsLXMmk8GxY8fw53/+5/zCt8Hej9HPzQWtikQiyOVyRrK/oJMd4QelaRpu3rwZ6ESFfuCVBIA7d+74XYW2CFOaZmCvA0/eZHTu3Dmsrq4yP36bOnHTVj8Lh8MdaZPvJzdu3GCAcMAg0efMX2rzFUM0GjXSJzA/PhG1ayiDhDmFcSwWc72T0y09cSspjuXrZZpkexNRsxTIBx1HH4lEcP36dWia1jDpjd/vjYj6w1AGidnZWTx48AD1eh2FQgH/9m//1rCNvPlmbGwMQghcv34dZ8+eNUY+xONxaJqGYrEIRVFQqVSgaRreeecdo4zl5WVMTU1BCIFLly7h/fff97yPTvnOd74DAPjZz342cO+NiHqghxlnO66dVNIyZ745zbFMDYwW0hPbt3daBluqZDn3gNd9eOVUl2br++W9MRW8d+hAqnDqvEFIFT50o5vkL2qZggBwHuNtTk9stri46HmuZFVVMTo6inw+j/PnzyMSiVg6QTuxj3b003t7+vSpkXaamnv06BEOHz7sdzXI5NGjR35X4eD8jlIH0c4vTbj86rYvd9uu2Xr7ssePH1tm37JPYrLfPrxqVo68SjL/gu+X9zYzM2OZIY4PPvr10c+Gsk+iFQdJT3zs2DEUCgWUSiWoqopkMumYubITKZDdfPzxxwDgOG9xP7y3mZkZx3kE+Ggcoru+vu57PfiwPgYhZdDQBQmZdni/DtROpCcOhULQdR3RaBR37txBqVSyzHbVqRTIbmq1Gm7fvg1FUSw3HA3CeyOiHhF9rJ3mJjnJuaIoxoTvcj5e4JsJ2M0T3JsflUrFsk7OkWvu/JYdusBeM4/cT6VSsTTLNNuHEHtzDu/X0Wver3m+3lKpZEw8b+5gDsp784Id194B7LgOokHouB66K4nx8XFUKhWMjY3hxRdfxNzcHF566aWG1M7N0hO3kmr6hz/8ITY3NxEKhbC5uWm5i3W/FMj7CYVClv3KXPuhUAhbW1tIpVIoFAoNd5H2w3sjomBgqnAKLH6+3nUqVTh1FlOFExHRQGOQICIiVwwSREOOo86cLS8vMzEmGCSIXOm63nTOjqCX70WtVsPCwgJOnjxpDHpwSyop15sfQaXrOorFIlZXV5tOJqZpGmKxGGKxWMMc2OfOnWOqfXDSISJX9sy5/Vb+fnRdRyKRQCqVwsTEBOr1Ou7du4d4PA4ADelThBCo1WoYHR1FtVoN9NwLmUwGwF4aGDcbGxu4e/cucrkcAODtt9/G559/jqtXrwLYS7efSqWQSCSQy+WGdvIuXkkQOdB1Haurq31bvhdy5jk57Wc4HMb09DSAvZPrxsZGw2tkYAhygAD2AlyzHGFPnz5FPB5HKpVCOBxGOByGqqp48803LTfaTkxMYGxszJibZRgxSNDAMc8XYp7vQnJqLrEvy2QyRvODXF6r1YzmCQBYXV1FKBTC3NycJf1Iu+UDB59DxKtarYZkMumYrkXWLx6POwYKJ/sd81bmKenFPCQfffQRAOCFF14wln3rW98CAPz85z+3bDs1NYVkMjm0zU4MEjRwZmdn8cUXX0CIveldNU2zzM5nnvJVqlQqlufmX6Hi6zw8o6OjRtt1sVjE1atXUa/XAQDHjx83AkW75feSzE569OhRx/U3btxAOp1GPB73NAfIfsfc6zwlvZqH5MGDBwBgublTXh3Z+ybkMRqIjK7t8OlO745g2obB1s7nK1OsmFOR7OzsCAAin88by+CQndO+zMs2QuylQAGsmXDbLb9daDEtRzqddt23XF6v141Mv+b5V+yv6+Qx79QcK8322epymZbGnunYC6blIAoYOfeEuc38xIkTAL6Z46LTotEoAFgSHAZdsw5dKRwOG23xzZpbOnnMzfOQmJvhvNS3W2SHdT99vp3EIEEDZWVlpWGZ/CO3NyPQ/iKRCEqlUkPzkVknj7ncXjik3e4kRVFc16mq2tF99TsGCRoo8o/f6Vdvt//4B/XkEo1GUSgUoGmaMbTUrBvHvJtzrADOdZYd6K+88kpX991vGCRooMgEd0+ePDGWyV+/U1NTXdmnPKFduHChK+V3gzzZe72jWGZJdmr26eQx79U8JN/73vcAWOv82WefWdbZyYzGw4ZBggbK+fPnoSgKlpaWjF+J9+7dg6qqlomX5C9ceYIvFovGurm5OQDWX5v2k5QcGqrrOnK5HBRFsTRhtFt+r4bAyjne7UFCHjOnq4Lp6WnHE6WXY24uT+7TvG+5/uLFiwD2+iBk6vvR0VEj2MihsV5GO5nLt7/P8fFxZLNZfPDBB9B1Hbqu44MPPkA2m21IZy+vME6dOrXvPgeSr93mB8TRTYOt3c+3Wq2KbDZrjFTJ5/OWCZmE2JskSY7cKRQKQgghFEUR+XzeGKUjRy2l02nLZEsAjEmdAIhsNtux8r1MNOUELY5ukpNC7ezsWMqwP5woiuJYXrNj7lSu274qlYox+kpVVctEVel0Wqiq6lgHM6f34vR+CoWCMQnZ/fv3HcuSI7Xsk3d5MQijmzifBAVWED9fOdomaH827cwnIa9ezJNFeaHruu8pKmKxGAOdRjMAABGfSURBVAqFQk/2NT8/j5GRkZaPE8D5JIiojyUSCTx48MDSFOaF3wGiWCwilUr1ZF/lchnlchmJRKIn+wsiBgkij+xpJvqdvA9iaWmp43c0d8v29jaOHDli5Jvqpt3dXaysrGBtbc33wOgnBgkij8zze5v/388ikQhyuRy2trb8roonk5OTRqd7t2mahps3bwY+mWG3MVU4kUf93K7cTDgcbqu9fdDxmOzhlQQREblikCAiIlcMEkRE5IpBgoiIXPV9x/Xdu3fx5Zdf+l0N6gI5yculS5d8rkl/eO+99/CTn/zE72qQiUyj3s/6+o5rTdOMScyJOmFrawsvvfQSnn/+eb+rQgPi6NGjWFpa8rsabevrIEHUae2ktyAaZOyTICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEFERK4YJIiIyBWDBBERuWKQICIiVyEhhPC7EkR+WFtbw9/93d/h+PHjxrJf/vKX+P3f/3389m//NgDgv//7v/Hd734XP/3pT/2qJpGvnvW7AkR+qVar+PLLL/Gf//mfluW6rluea5rWy2oRBQqbm2hoxeNxhEKhpts8++yzePfdd3tUI6LgYXMTDbU/+ZM/wccffwy3P4NQKIRPP/0UL774Yo9rRhQMvJKgofY3f/M3OHTokOO6Z555BqdOnWKAoKHGIEFD7Qc/+AF+/etfO64LhUK4cuVKj2tEFCwMEjTUnn/+eZw+fdr1amJqaqrHNSIKFgYJGnpvvPFGQ5/EoUOHcObMGfzBH/yBT7UiCgYGCRp6f/EXf9FwJSGEwBtvvOFTjYiCg0GChl44HMb58+fx7LPf3DZ0+PBhfP/73/exVkTBwCBBBGB2dhZfffUVgL17I15//XX87u/+rs+1IvIfgwQRgNdffx2/9Vu/BQD46quvcPnyZZ9rRBQMDBJEAH7zN38Tf/3Xfw0A+J3f+R1cuHDB5xoRBUNgczft7OzgV7/6ld/VoCHyh3/4hwCAF198EYVCwefa0DA5dOgQYrGYpV8sKAKblmO/nDpERIPkxz/+cSAHSwQvbJmsr69jZmbG72pQgN29exeXL192zb1E35D9LOvr6z7XhOxCoRD+53/+x+9qOGKfBBERuWKQICIiVwwSRETkikGCiIhcMUgQEZErBgkiInLFIEH0tfn5eczPz/tdjcCq1WpYXl72uxqBs7y8DF3X/a5G1zBIEAWEruuBvYm0VqthYWEBJ0+eRCgUQigUcg2ocr35EVS6rqNYLGJ1dRWxWMx1O03TEIvFEIvFoGmaZd25c+cwOzuLWq3W7er6ItA30xH10q1bt3zd/8OHD33dvxtd15FIJJBKpTAxMYF6vY579+4hHo8DaDxuQgjUajWMjo6iWq0iEon4UW1PMpkMAGBxcdF1m42NDdy9exe5XA4A8Pbbb+Pzzz/H1atXAQDRaBSpVAqJRAK5XA7hcLj7Fe8hXkkQBYCu61hdXfW7Go7W1tYQjUYxMTEBYG/+jenpaQB7J9eNjY2G18jAEOQAAewFuGY/Dp4+fYp4PI5UKoVwOIxwOAxVVfHmm2+iXC4b201MTGBsbAxra2u9qHZPMUgQYa85ZWNjw2hysD/XNA2hUAixWAxPnz41tpHNEACwurqKUCiEubk57O7uGmU7NbvYl2UyGaMZw7zc736SWq2GZDKJM2fOOK7PZDKIx+OOgcKJruvY2Ngw3uPq6qqlmcbLcTdvu7y8bKzf3t5u8126++ijjwAAL7zwgrHsW9/6FgDg5z//uWXbqakpJJPJwWt2EgEFQKyvr/tdDQq49fV10YmvsaIoAoBRlvn5zs6OEEKISqUiAAhVVYUQwlhv3qZerwtVVQUA8fjxYyGEENVq1VK2uSzzMvtzIYRIp9MinU4f+P0JIcTMzIyYmZlp6TWFQkEAEJVKpWGdrGs6nRYARKlUclxvpiiKyGazQoi946IoilAURdTrdWP9fsfd/Np8Pi+EEOL+/fuOdfDK6dgLIYzP0ml7RVEsy2Q9C4VCW/sP6vmOQYL6WqeChBCNJwqnE4eXbUqlkgAgMpnMgcvqpHaChAwATuTyer1unNxlYDSvl+SJvFqtGst2dnYEAONkL1+337HK5/OO27QbUN2OfSvL6/V6w+feyv6Der5jcxNRh0WjUQBAMpn0uSYH16xDVwqHw0ZbfLPmls3NTQDWfooTJ04A2Mvm2wq5vb3Zzkt9u0V2WA/C527GIEFEBxaJRFAqlaBpGhKJhON9AysrKw3L5InVPqx0P3J7sdcaYnl0kqIorutUVe3ovoKKQYKoS4blJCJFo1EUCgVommYMLTWTJ1ynK412j5V5gEA3ONVZdqC/8sorXd13UDBIEHWYPHENwjzZ8mTv9Y5iRVGQz+cdm33kBGJPnjwxlslyp6amWqpXNpsFAORyOaOMbtwR/r3vfQ+Atc6fffaZZZ1dOp3uaB38xiBBBDQMwzQ/lych84nS/mtYDgHVdR25XA6KoliaKuQvZRlAisWisW5ubg6A9VerPNn5PQT22LFjABqDhHz/TlcF09PTjifK8+fPQ1EULC0tGa+7d+8eVFXF5ORkQ3nNjvvFixcB7PVBjIyMIBQKYXR01Ag2cmis+V4GN+by7e9zfHwc2WwWH3zwAXRdh67r+OCDD5DNZjE+Pm7ZVl5hnDp1at999hVfu82bQIB7+yk4OjW6CabhrE4Pp23My0qlkjHCJ5vNGkM6pUqlYqyXQyTlEE452keOikqn08Yyv4fAyuG7cjiqEM7Hyol9iKgsL5vNGq/L5/OWY+X1uAuxd0zl6CtVVS3DdNPptFBV1bEOZs0+bzM5FFhRFHH//n3HsuRILfPoLa+CfL4LCRHMyYFDoRDnuKZ9+T3HtRxVE9A/I4t257iWVzU3btxo6XW6rvueoiIWi6FQKPRkX/Pz8xgZGWn5OAHBPt+xuYmImkokEnjw4IGlicwLvwNEsVhEKpXqyb7K5TLK5TISiURP9tdLAx0k7Lf4E3WSvR9jUMn7IJaWljy18QfB9vY2jhw5YuSb6qbd3V2srKxgbW3N98DYDQMdJBYWFhCPx1segx0UXtMYN+OUtlk+lpeXoWnaQOfC76bR0VHH/w+iSCSCXC6Hra0tv6viyeTkpNHp3m2apuHmzZuBT2bYroEOEnfu3PG7CgeSyWTwz//8z3jzzTfbDnRCCFSrVeN5vV43bjo6d+4cVldXBzoXfjeJLt7EFUThcLit9vZBd+PGjYENEMCAB4l+t18aY6/MX2Dz5XA0GjXSKbjdJUtEw22ggoQ5DXEsFnO9G9MtxXAraYrl62WqY/vsW71IYwwcfBx9JBLB9evXoWlaw6Q3g3SciKhNPg293RfaGDesKIpQVdUYdy0zRZrfZrMUw17TFGcyGWNMdr1eb8iU2as0xkJ4H0ffrAyZvdJrKuYgHadOZoEddO3cJ0G90c75rlcC+9fV6kGTN7uYUxXLk5/5JLJfimGnk6l9GWw3zMgbjrzuo1XNTvCdKqNfjxODhHcMEsEV5CAxMHNc/+xnPwMAy4gGp+Fo5hTDZouLi57b/1VVxejoKPL5PM6fP49IJGLpuOzEPvzWb8fp0qVLLW0/jB49egSAx4paMzB9Ek5piJ10IsXwW2+9BUVREI/HMTIy0pBUrFdpjDtFdlib8+3wOBERAAzMlUSrdnd32x5HfezYMRQKBZTLZaysrBiTjNiHBx5kH7308ccfA4DjPMb9cpw+/PDDA71+GLSbloO6z341HSQDcyUhUwfvd0doJ1IMh0Ih6LqOaDSKO3fuoFQqWWaj6lUa406o1Wq4ffs2FEUxMnECPE5E9LVedoC0Ai125MjRNYqiGCNq5GgZmEbdmCelNz8qlYplnRwhZe78lp2w+LpzVe6nUqlY5rVtto9WmfdvzywqhLfRTW5lyJFKiqI0ZK7sl+PEjmvv2HEdXK2e73ppYK4kxsfHUalUMDY2hhdffBFzc3N46aWXjElQbt68CWDvvoBKpWK0v6uqikqlgvHxcUtqhZGREcu/gDX1wg9/+ENsbm4iFAphc3PT0oTSbB+tCIVClv3LvPmdKCMUCmFrawupVAqFQqHhjtF+Ok5E1D1MFU59ze9U4f2EfRLBFeTz3cBcSRARUecxSBBRW4ZxkMHy8vLQ5ThjkOixZqm7zQ/qD7qud/Xz6nb57arValhYWMDJkyeN76xbDrF++n7vl57/3LlzQ5c1eWjvk/AL284Hiz0pYr+V3w5d15FIJJBKpTAxMYF6vY579+4hHo8DQMPd8kII1Go1jI6OolqtBjqtdiaTAbB317+TaDSKVCqFRCKBXC43kJMM2fFKgqhNuq5jdXW1b8tv19raGqLRqDHrWzgcxvT0NIC9k+vGxkbDa2RgCHKAALyl55+YmMDY2JiRZn/QMUjQUDKnlTenMpecmkbsyzKZjJFaRC6v1WrQNM1oqlhdXUUoFMLc3JwldX275QMHTw9/ELVaDclk0vHufGCvzvF43DFQONnvc2glLX0v085PTU0hmUwORbMTgwQNpdnZWXzxxRfGzH2aplkmXjLP5idVKhXLc/MvTvF1zqnR0VHEYjFomoZisYirV6+iXq8DAI4fP24EinbL95tMEnj06FHH9Tdu3EA6nUY8Hvc0H/Z+n0MikTCmIC4Wi1AUBZVKBZqm4Z133jHKqdVqSCQSGBsbgxAC169fx9mzZ7s2J7d8//J4DDR/7uHbHwJ8ByIFRzt3XMs78c13me/s7AgAxtwWQnhPh77fNkLs3d0OwHLHebvlt6sTd1zb5wQxk8vr9box54g5db/9dZ38HHqdnl9mGDB/ngcR5PMdryRo6GxubgKwto+fOHECwDfpyzstGo0CgCV3VT9y69A1C4fDRnt9syaZTn4O5rTz5qY5L/Vth+yw7vfP0wsGCRo6Tmnl5R+97AOgg4lEIiiVSg3NR2ad/ByYdr57GCRo6CiKAgCOv3BVVe3qvrtdfpBEo1EUCgVommYMLTXrxufgNq89tY9BgoaOzI/z5MkTY5n8pTs1NdWVfcqT14ULF7pSfq/Ik73Xu45lgk2nZp9Ofg5+pZ03T9Q1qBgkaOicP38eiqJgaWnJ+BV77949qKpqmVND/pqVJ/hisWism5ubA2D9NWw/IclhoLquI5fLQVEUY/uDlO/nEFg5OZQ9SMjj6HRVMD097Xgy9fI5mMuT+zTvW66/ePEigL0+CJnpeHR01Ag2cmisl9FO5vLdgqEcfnvq1Kl9y+t7vnabN4EA9/ZTcLQ7n0S1WhXZbNYYxZLP5xvm66hUKsYonUKhIIQQQlEUkc/njRE5ctRSOp22zKMBwJivA4DIZrMdK9/LHCJOOjG6Sc4BsrOzYyyT79f8cKIoimN5zT4Hp3Ld9lWpVIzRV6qqWuYlSafTQlVVxzqYOb0Xp/cjR2HZ52FpV5DPd0wVTn0tiKnC5ciaINUJ6FyqcHlFY5+Gdj+6rvuexiIWi6FQKBy4nPn5eYyMjLR8DNwE+XzH5iYiakkikcCDBw8szWNe+B0gisUiUqnUgcspl8sol8tIJBIdqFXwMUgQdZA9pcQgkvdBLC0tde2O5k7b3t7GkSNHjHxT7drd3cXKygrW1tZ8D3q9wiBB1EHmqVvN/x80kUgEuVwOW1tbflfFk8nJSaPT/SA0TcPNmzcDn6iwk5gqnKiDgtYP0U3hcLhjbfL9YtjeL8ArCSIiaoJBgoiIXDFIEBGRKwYJIiJyxSBBRESuAn3HNRHRsPjxj3+M73//+35Xo0Fgh8B+9NFH+NWvfuV3NYiIuu7QoUN4/fXX/a6Go8BeSRARkf/YJ0FERK4YJIiIyBWDBBERuXoWwP/zuxJERBRM/x/+GIxjLTyY9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='./Basic3.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7568.0\n",
      "7643.0\n",
      "7718.0\n",
      "7793.0\n",
      "7868.0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[101, 10], [102, 10], [103, 10], [104, 10], [105, 10]])\n",
    "for i in range(len(x)):  # 실제값 비교 목적으로 산출\n",
    "    print((x[i][0] * x[i][1]) / 2 * 5 * 3 - 7)\n",
    "\n",
    "y = np.array([7568, 7643, 7718, 7793, 7868]) # 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "[[7567.994 ]\n",
      " [7642.9946]\n",
      " [7717.994 ]\n",
      " [7792.9937]\n",
      " [7867.994 ]]\n",
      "x: [101  10], 실제값: 7568, 예측값: 7567.99414, 정제된값: 7568\n",
      "x: [102  10], 실제값: 7643, 예측값: 7642.99463, 정제된값: 7643\n",
      "x: [103  10], 실제값: 7718, 예측값: 7717.99414, 정제된값: 7718\n",
      "x: [104  10], 실제값: 7793, 예측값: 7792.99365, 정제된값: 7793\n",
      "x: [105  10], 실제값: 7868, 예측값: 7867.99414, 정제된값: 7868\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(x) # 모델 사용\n",
    "print(p.shape)\n",
    "print(p)\n",
    "for i in range(len(x)):\n",
    "    fmt = 'x: {0}, 실제값: {1}, 예측값: {2:.5f}, 정제된값: {3:.0f}'\n",
    "    print(fmt.format(x[i], y[i], p[i][0], p[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선이 이루어지지않으면 Kernel restart를 이용한 초기화 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
