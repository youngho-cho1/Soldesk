{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit 개선을 위한 L1, L2 규제의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autosave 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 사용\n",
    "from tensorflow.keras.layers import Dense       # 전결합\n",
    "from tensorflow.keras.layers import Dropout     # 특정 node를 사용안함.\n",
    "from tensorflow.keras.callbacks import EarlyStopping # 학습 자동 중지\n",
    "from tensorflow.keras import regularizers   # L1, L2 규제 적용\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold  # K 겹 교차 검증\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "#font_name = font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgunsl.ttf\").get_name()\n",
    "#rc('font', family=font_name)           # 맑은 고딕 폰트 지정\n",
    "plt.rcParams[\"font.size\"] = 12         # 글자 크기\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 4) # 10:4의 그래프 비율\n",
    "plt.rcParams['axes.unicode_minus'] = False  # minus 부호는 unicode 적용시 한글이 깨짐으로 설정\n",
    "\n",
    "# Jupyter에게 matplotlib 그래프를 출력 영역에 표시할 것을 지시하는 명령\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(470, 18)\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('./Survival.csv', delimiter=\",\", dtype=np.float64)\n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470, 17)\n",
      "(470,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:, 0:17] # 0 ~ 16: 17개\n",
    "print(X.shape)\n",
    "Y = data[:, 17]   # 17: 1개\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(43,)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split 분할을 통한 훈련, 검증, 테스트 데이터의 분리\n",
    "seed = 0\n",
    "# 90%: 분할대기(x_train_all), 10%: 테스트(x_test)\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(X, Y,\n",
    "                                                          stratify=Y,\n",
    "                                                          test_size=0.1,\n",
    "                                                          random_state=seed)\n",
    "# 약한 Overfit\n",
    "# 나머지 데이터 90%를 분할, 70%: 훈련(x_train), 30%: 검증(x_val)\n",
    "\n",
    "# 강한 Overfit\n",
    "# 나머지 데이터 90%를 분할, 90%: 훈련(x_train), 10%: 검증(x_val)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                  stratify=y_train_all,\n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=seed)\n",
    "\n",
    "print(y_val[0:100])\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1l2():\n",
    "    tf.random.set_seed(0)\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) \n",
    "    model.add(Dense(128, input_shape=(17, ), activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001))) \n",
    "    model.add(Dense(64, activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # 오차가 16번 증가되면 종료, Overfit 발생을위해 과도한 학습 진행\n",
    "    es = EarlyStopping(monitor='loss', patience=16, restore_best_weights=True)\n",
    "\n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[es])\n",
    "    \n",
    "    fig, loss_ax = plt.subplots()\n",
    "    # plt.figure(figsize=(6,4)) # ERROR\n",
    "    fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "    acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "    # 왼쪽 y 축 설정\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 1.0229]) # 값을 반영하여 변경\n",
    "\n",
    "    # 오른쪽 y 축 설정\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    acc_ax.set_ylim([0.0, 1]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "    # 축 레이블 설정\n",
    "    loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "    loss_ax.set_ylabel('loss')   # 오차\n",
    "    acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "    loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "    acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=1, verbose=0)\n",
    "    print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout 사용의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 사용의 경우\n",
    "def dropout_use():\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) # 첫번째 은닉층\n",
    "    model.add(Dense(128, input_shape=(17, ), activation='relu')) # 첫번째 은닉층\n",
    "    model.add(Dropout(0.2)) # 20% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2)) # 20% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # 오차가 16번 증가되면 종료, Overfit 발생을위해 과도한 학습 진행\n",
    "    es = EarlyStopping(monitor='loss', patience=16, restore_best_weights=True)\n",
    "\n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[es])\n",
    "    \n",
    "    fig, loss_ax = plt.subplots()\n",
    "    # plt.figure(figsize=(6,4)) # ERROR\n",
    "    fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "    acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "    # 왼쪽 y 축 설정\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 1.0229]) # 값을 반영하여 변경\n",
    "\n",
    "    # 오른쪽 y 축 설정\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    acc_ax.set_ylim([0.0, 1]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "    # 축 레이블 설정\n",
    "    loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "    loss_ax.set_ylabel('loss')   # 오차\n",
    "    acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "    loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "    acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=1, verbose=0)\n",
    "    print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')\n",
    "   \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1, L2, Dropout 사용의 경우\n",
    "def l1l2_dropout():\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) \n",
    "    \n",
    "    model.add(Dense(128, input_shape=(17, ), activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001)))\n",
    "    model.add(Dropout(0.1)) # 10% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(64, activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001)))\n",
    "    model.add(Dropout(0.1)) # 10% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    # 오차가 16번 증가되면 종료, Overfit 발생을위해 과도한 학습 진행\n",
    "    es = EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[es])\n",
    "    \n",
    "    fig, loss_ax = plt.subplots()\n",
    "    # plt.figure(figsize=(6,4)) # ERROR\n",
    "    fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "    acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "    # 왼쪽 y 축 설정\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 1.0229]) # 값을 반영하여 변경\n",
    "\n",
    "    # 오른쪽 y 축 설정\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    acc_ax.set_ylim([0.0, 1]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "    # 축 레이블 설정\n",
    "    loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "    loss_ax.set_ylabel('loss')   # 오차\n",
    "    acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "    loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "    acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=1, verbose=0)\n",
    "    print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')\n",
    "\n",
    "    return model, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 13,151\n",
      "Trainable params: 13,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.7275 - accuracy: 0.8137 - val_loss: 0.5338 - val_accuracy: 0.8605\n",
      "Epoch 2/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.7837 - val_loss: 0.5102 - val_accuracy: 0.8605\n",
      "Epoch 3/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8574 - val_loss: 0.4730 - val_accuracy: 0.8605\n",
      "Epoch 4/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.8587 - val_loss: 0.5038 - val_accuracy: 0.8605\n",
      "Epoch 5/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8368 - val_loss: 0.5899 - val_accuracy: 0.8605\n",
      "Epoch 6/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8724 - val_loss: 0.4928 - val_accuracy: 0.8605\n",
      "Epoch 7/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8347 - val_loss: 0.6263 - val_accuracy: 0.8605\n",
      "Epoch 8/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8562 - val_loss: 0.4751 - val_accuracy: 0.8605\n",
      "Epoch 9/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8345 - val_loss: 0.4528 - val_accuracy: 0.8605\n",
      "Epoch 10/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8654 - val_loss: 0.4591 - val_accuracy: 0.8605\n",
      "Epoch 11/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8844 - val_loss: 0.4674 - val_accuracy: 0.8605\n",
      "Epoch 12/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8603 - val_loss: 0.4554 - val_accuracy: 0.8605\n",
      "Epoch 13/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8536 - val_loss: 0.4877 - val_accuracy: 0.8605\n",
      "Epoch 14/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8542 - val_loss: 0.4616 - val_accuracy: 0.8605\n",
      "Epoch 15/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.8441 - val_loss: 0.4498 - val_accuracy: 0.8605\n",
      "Epoch 16/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8244 - val_loss: 0.4501 - val_accuracy: 0.8605\n",
      "Epoch 17/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8328 - val_loss: 0.4519 - val_accuracy: 0.8605\n",
      "Epoch 18/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8793 - val_loss: 0.4676 - val_accuracy: 0.8605\n",
      "Epoch 19/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8716 - val_loss: 0.4475 - val_accuracy: 0.8605\n",
      "Epoch 20/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8498 - val_loss: 0.8550 - val_accuracy: 0.8605\n",
      "Epoch 21/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8434 - val_loss: 0.4870 - val_accuracy: 0.8605\n",
      "Epoch 22/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.8562 - val_loss: 0.4413 - val_accuracy: 0.8605\n",
      "Epoch 23/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8206 - val_loss: 0.4463 - val_accuracy: 0.8605\n",
      "Epoch 24/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.8259 - val_loss: 0.4505 - val_accuracy: 0.8605\n",
      "Epoch 25/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8834 - val_loss: 0.4591 - val_accuracy: 0.8605\n",
      "Epoch 26/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8608 - val_loss: 0.4465 - val_accuracy: 0.8605\n",
      "Epoch 27/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8389 - val_loss: 0.4569 - val_accuracy: 0.8605\n",
      "Epoch 28/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8412 - val_loss: 0.4528 - val_accuracy: 0.8605\n",
      "Epoch 29/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8560 - val_loss: 0.4479 - val_accuracy: 0.8605\n",
      "Epoch 30/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8748 - val_loss: 0.4417 - val_accuracy: 0.8605\n",
      "Epoch 31/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8389 - val_loss: 0.4428 - val_accuracy: 0.8605\n",
      "Epoch 32/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8259 - val_loss: 0.5234 - val_accuracy: 0.8605\n",
      "Epoch 33/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8553 - val_loss: 0.4491 - val_accuracy: 0.8605\n",
      "Epoch 34/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8675 - val_loss: 0.4345 - val_accuracy: 0.8605\n",
      "Epoch 35/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8604 - val_loss: 0.4341 - val_accuracy: 0.8605\n",
      "Epoch 36/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8546 - val_loss: 0.4345 - val_accuracy: 0.8605\n",
      "Epoch 37/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8120 - val_loss: 0.4568 - val_accuracy: 0.8605\n",
      "Epoch 38/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8597 - val_loss: 0.4400 - val_accuracy: 0.8605\n",
      "Epoch 39/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.8344 - val_loss: 0.4340 - val_accuracy: 0.8605\n",
      "Epoch 40/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.8418 - val_loss: 0.4320 - val_accuracy: 0.8605\n",
      "Epoch 41/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8541 - val_loss: 0.4387 - val_accuracy: 0.8605\n",
      "Epoch 42/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8462 - val_loss: 0.4326 - val_accuracy: 0.8605\n",
      "Epoch 43/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.8262 - val_loss: 0.4303 - val_accuracy: 0.8605\n",
      "Epoch 44/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8356 - val_loss: 0.4289 - val_accuracy: 0.8605\n",
      "Epoch 45/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.8210 - val_loss: 0.4557 - val_accuracy: 0.8605\n",
      "Epoch 46/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.8401 - val_loss: 0.4290 - val_accuracy: 0.8605\n",
      "Epoch 47/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8523 - val_loss: 0.4320 - val_accuracy: 0.8605\n",
      "Epoch 48/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8329 - val_loss: 0.4274 - val_accuracy: 0.8605\n",
      "Epoch 49/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8729 - val_loss: 0.4267 - val_accuracy: 0.8605\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8504 - val_loss: 0.4299 - val_accuracy: 0.8605\n",
      "Epoch 51/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.8326 - val_loss: 0.4254 - val_accuracy: 0.8605\n",
      "Epoch 52/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.8467 - val_loss: 0.4348 - val_accuracy: 0.8605\n",
      "Epoch 53/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.8191 - val_loss: 0.4247 - val_accuracy: 0.8605\n",
      "Epoch 54/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8639 - val_loss: 0.4227 - val_accuracy: 0.8605\n",
      "Epoch 55/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8544 - val_loss: 0.4218 - val_accuracy: 0.8605\n",
      "Epoch 56/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8445 - val_loss: 0.4370 - val_accuracy: 0.8605\n",
      "Epoch 57/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8514 - val_loss: 0.4253 - val_accuracy: 0.8605\n",
      "Epoch 58/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8678 - val_loss: 0.4202 - val_accuracy: 0.8605\n",
      "Epoch 59/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.8283 - val_loss: 0.4202 - val_accuracy: 0.8605\n",
      "Epoch 60/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8693 - val_loss: 0.4192 - val_accuracy: 0.8605\n",
      "Epoch 61/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8472 - val_loss: 0.4203 - val_accuracy: 0.8605\n",
      "Epoch 62/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.8253 - val_loss: 0.4182 - val_accuracy: 0.8605\n",
      "Epoch 63/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8373 - val_loss: 0.4195 - val_accuracy: 0.8605\n",
      "Epoch 64/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8561 - val_loss: 0.4209 - val_accuracy: 0.8605\n",
      "Epoch 65/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8576 - val_loss: 0.4212 - val_accuracy: 0.8605\n",
      "Epoch 66/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8167 - val_loss: 0.4279 - val_accuracy: 0.8605\n",
      "Epoch 67/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8675 - val_loss: 0.4189 - val_accuracy: 0.8605\n",
      "Epoch 68/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.8223 - val_loss: 0.4435 - val_accuracy: 0.8605\n",
      "Epoch 69/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8073 - val_loss: 0.4232 - val_accuracy: 0.8605\n",
      "Epoch 70/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.8633 - val_loss: 0.4165 - val_accuracy: 0.8605\n",
      "Epoch 71/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8632 - val_loss: 0.4196 - val_accuracy: 0.8605\n",
      "Epoch 72/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8481 - val_loss: 0.4177 - val_accuracy: 0.8605\n",
      "Epoch 73/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8569 - val_loss: 0.4178 - val_accuracy: 0.8605\n",
      "Epoch 74/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8662 - val_loss: 0.4176 - val_accuracy: 0.8605\n",
      "Epoch 75/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8732 - val_loss: 0.4171 - val_accuracy: 0.8605\n",
      "Epoch 76/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8364 - val_loss: 0.4168 - val_accuracy: 0.8605\n",
      "Epoch 77/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8818 - val_loss: 0.4187 - val_accuracy: 0.8605\n",
      "Epoch 78/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8332 - val_loss: 0.4194 - val_accuracy: 0.8605\n",
      "Epoch 79/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.8375 - val_loss: 0.4162 - val_accuracy: 0.8605\n",
      "Epoch 80/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.8324 - val_loss: 0.4158 - val_accuracy: 0.8605\n",
      "Epoch 81/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8680 - val_loss: 0.4161 - val_accuracy: 0.8605\n",
      "Epoch 82/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3933 - accuracy: 0.8693 - val_loss: 0.4160 - val_accuracy: 0.8605\n",
      "Epoch 83/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4207 - accuracy: 0.8501 - val_loss: 0.4157 - val_accuracy: 0.8605\n",
      "Epoch 84/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.8264 - val_loss: 0.4179 - val_accuracy: 0.8605\n",
      "Epoch 85/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.8259 - val_loss: 0.4252 - val_accuracy: 0.8605\n",
      "Epoch 86/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8218 - val_loss: 0.4177 - val_accuracy: 0.8605\n",
      "Epoch 87/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8872 - val_loss: 0.4172 - val_accuracy: 0.8605\n",
      "Epoch 88/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8409 - val_loss: 0.4161 - val_accuracy: 0.8605\n",
      "Epoch 89/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8426 - val_loss: 0.4189 - val_accuracy: 0.8605\n",
      "Epoch 90/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8517 - val_loss: 0.4130 - val_accuracy: 0.8605\n",
      "Epoch 91/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8507 - val_loss: 0.4158 - val_accuracy: 0.8605\n",
      "Epoch 92/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8612 - val_loss: 0.4162 - val_accuracy: 0.8605\n",
      "Epoch 93/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8529 - val_loss: 0.4151 - val_accuracy: 0.8605\n",
      "Epoch 94/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8360 - val_loss: 0.4186 - val_accuracy: 0.8605\n",
      "Epoch 95/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8588 - val_loss: 0.4185 - val_accuracy: 0.8605\n",
      "Epoch 96/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.8478 - val_loss: 0.4145 - val_accuracy: 0.8605\n",
      "Epoch 97/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8604 - val_loss: 0.4145 - val_accuracy: 0.8605\n",
      "Epoch 98/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8439 - val_loss: 0.4143 - val_accuracy: 0.8605\n",
      "Epoch 99/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8372 - val_loss: 0.4180 - val_accuracy: 0.8605\n",
      "Epoch 100/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8118 - val_loss: 0.4331 - val_accuracy: 0.8605\n",
      "Epoch 101/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8639 - val_loss: 0.4152 - val_accuracy: 0.8605\n",
      "Epoch 102/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8471 - val_loss: 0.4160 - val_accuracy: 0.8605\n",
      "Epoch 103/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.8391 - val_loss: 0.4154 - val_accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실값: 0.42680490016937256 /정확도: 85.10638475418091 %\n"
     ]
    }
   ],
   "source": [
    "model, hist = l1l2() \n",
    "\n",
    "# model, hist = dropout_use() \n",
    "\n",
    "# model, hist = l1l2_dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
